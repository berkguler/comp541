{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{String,1}:\n",
       " \"doganay_experiment\"\n",
       " \"idil_experiment\"\n",
       " \"istenc_experiment\"\n",
       " \"omer_experiment\"\n",
       " \"ozan_experiment\"\n",
       " \"yahya_experiment\"\n",
       " \"zaid_experiment\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Pkg; #Pkg.add(\"IterTools\"); Pkg.add(\"Knet\"); Pkg.add(\"Plots\"); Pkg.add(\"CUDA\"); Pkg.add(\"PlotlyJS\")\n",
    "using Knet\n",
    "using Printf\n",
    "using Statistics: mean\n",
    "using Base.Iterators: flatten\n",
    "using IterTools: ncycle, takenth\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using Plots; plotlyjs()\n",
    "using DelimitedFiles, Statistics, Random\n",
    "import CUDA\n",
    "array_type=(CUDA.functional() ? KnetArray{Float32} : Array{Float32})\n",
    "dataset_directory_path = \"../DATA\"\n",
    "dataset_directory = filter(x -> isdir(joinpath(dataset_directory_path, x)), readdir(dataset_directory_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message(message) = run(`curl https://notify.run/zrqfxE0M1ypL5Dv4 -d $message`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Knet.load(\"raw_data.jld2\",\"train\");\n",
    "test_data = Knet.load(\"raw_data.jld2\",\"test\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_and_convert (generic function with 1 method)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_and_convert(string_array,splitter)\n",
    "    Rlength = length(string_array)\n",
    "    Clength = length(split(string_array[1],splitter))\n",
    "    Mdata = zeros(Float64,Rlength,Clength)\n",
    "    for i in 1:Rlength\n",
    "        row =  map(x->tryparse(Float64,x),split(string_array[i],splitter))\n",
    "        Mdata[i,:] = row\n",
    "    end\n",
    "    return Mdata\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_history = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_selection (generic function with 1 method)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function data_selection(participant_directory_path)\n",
    "    data_matrix = Array{Float32}(undef,0,9);\n",
    "    participant_directory = readdir(participant_directory_path)\n",
    "    for raw_txt_files in participant_directory\n",
    "            txt_file_directory_path = joinpath(participant_directory_path, raw_txt_files)\n",
    "            txt_file_directory = readdir(txt_file_directory_path)\n",
    "            \n",
    "            raw_data_file = open(joinpath(txt_file_directory_path,txt_file_directory[4]))\n",
    "            raw_data = split_and_convert(readlines(raw_data_file),\",\")\n",
    "            close(raw_data_file)\n",
    "            \n",
    "            #To avoiding the colliding between subtask 3 and subtask 1\n",
    "            _, remain = divrem(size(raw_data,1),time_history)\n",
    "            \n",
    "            #  Velocity F_fint  F_h  subtask \n",
    "            #  1        2       3      4     \n",
    "            data_matrix = [data_matrix; raw_data[1:end-remain,:]]\n",
    "        end\n",
    "        \n",
    "    return data_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Array{Float32}(undef,0,9);\n",
    "train_data = Array{Float32}(undef,0,9);\n",
    "\n",
    "for participant_index in 1:length(dataset_directory)\n",
    "    #Participants: 1.doganay 2.idil 3.istenc 4.omer 5.ozan 6.yahya 7.zaid\n",
    "    participant_directory_path = joinpath(dataset_directory_path,dataset_directory[participant_index])\n",
    "    participant_directory = readdir(participant_directory_path)\n",
    "    \n",
    "    if participant_index != 5\n",
    "        data = data_selection(participant_directory_path)\n",
    "        train_data = [train_data;data]\n",
    "    else\n",
    "        data = data_selection(participant_directory_path)\n",
    "        test_data = [test_data;data]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Length (Descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_, _ = findmax(list_series)\n",
    "#min_ , _ = findmin(list_series)\n",
    "#mean_ = mean(list_series)\n",
    "#print(\"Max: \",max_,\" Min: \", min_ ,\" Mean: \", mean_)\n",
    "# Adding Related Time Series Length to the DATA\n",
    "#assign_durations(data_array,duration_list) = for i in 1:size(data_array)[1]; data_array[i] = [data_array[i],duration_list[i]];end\n",
    "##For the train_data\n",
    "#assign_durations(train_data,list_series[1:length(train_data)])\n",
    "##For the test_data\n",
    "#assign_durations(test_data,list_series[length(train_data)+1:end])\n",
    "# Sorting Data\n",
    "#sort!(train_data, by = x -> x[:][2],rev=true); \n",
    "#sort!(test_data, by = x -> x[:][2],rev=true); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pHRIHelper"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct pHRIHelper\n",
    "   measurements\n",
    "   subtasks\n",
    "   batchsize\n",
    "   time_history\n",
    "   ninstances\n",
    "   shuffled\n",
    "end\n",
    "\n",
    "function data_splitter(raw_data)\n",
    "    input = [raw_data[:,2] raw_data[:,3] raw_data[:,5]];\n",
    "    output = raw_data[:,end];\n",
    "    return input,output\n",
    "end\n",
    "\n",
    "\n",
    "function pHRIHelper(raw_data; batchsize = 128, time_history = 50, shuffled = true)\n",
    "   measurements, subtasks = data_splitter(raw_data)\n",
    "   ninstances, _ = divrem(length(subtasks),time_history+batchsize-2)\n",
    "   ninstances = convert(Int,ninstances)\n",
    "   return pHRIHelper(measurements,subtasks,batchsize,time_history,ninstances,shuffled)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State data stands for ninstances, But every iteration it gets 50 timesteps for each batchsize element.\n",
    "#Each element \n",
    "\n",
    "function Base.iterate(d::pHRIHelper, state=ifelse(d.shuffled, randperm(d.ninstances), 1:d.ninstances))\n",
    "    output = KnetArray(zeros(Int32,d.batchsize,d.time_history));        #time_steps,1\n",
    "    input = KnetArray(zeros(Float32,3,d.batchsize,d.time_history));        # X B T -> 3x16x50\n",
    "    needed_volume = d.batchsize+d.time_history-2;\n",
    "    related_measurements = d.measurements[state[1]:state[1]+needed_volume,:]\n",
    "    related_subtasks = d.subtasks[state[1]:state[1]+needed_volume];\n",
    "    buffer = zeros(time_history,1);\n",
    "    x_matrix = zeros(3,time_history);\n",
    "    y_matrix = zeros(1,time_history);\n",
    "    for time_step in 1:d.batchsize\n",
    "        buffer = time_step:time_step+time_history-1;\n",
    "        x_matrix = related_measurements[buffer,:];\n",
    "        y_matrix = related_subtasks[buffer];\n",
    "        input[:,time_step,:] = x_matrix';\n",
    "        output[time_step,:] = y_matrix;\n",
    "    end\n",
    "    new_state = state[2:end]\n",
    "    length(new_state) < 1 && return nothing\n",
    "    return ((input, output),new_state)    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Out of GPU memory trying to allocate 75.000 KiB\nEffective GPU memory usage: 99.97% (1.999 GiB/2.000 GiB)\nCUDA allocator usage: 1.526 GiB\nbinned usage: 116.578 KiB (116.578 KiB allocated, 0 bytes cached)\nDiscrepancy of 1.526 GiB between memory pool and allocator!\n",
     "output_type": "error",
     "traceback": [
      "Out of GPU memory trying to allocate 75.000 KiB\nEffective GPU memory usage: 99.97% (1.999 GiB/2.000 GiB)\nCUDA allocator usage: 1.526 GiB\nbinned usage: 116.578 KiB (116.578 KiB allocated, 0 bytes cached)\nDiscrepancy of 1.526 GiB between memory pool and allocator!\n",
      "",
      "Stacktrace:",
      " [1] alloc at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\pool.jl:298 [inlined]",
      " [2] CUDA.CuArray{UInt8,1}(::UndefInitializer, ::Tuple{Int64}) at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:20",
      " [3] CuArray at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:76 [inlined]",
      " [4] CuArray at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:77 [inlined]",
      " [5] KnetPtrCu(::Int64) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\kptr.jl:229",
      " [6] Knet.KnetArrays.KnetPtr(::Int64) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\kptr.jl:107",
      " [7] KnetArray at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:81 [inlined]",
      " [8] KnetArray at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:94 [inlined]",
      " [9] KnetArray at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:92 [inlined]",
      " [10] iterate(::pHRIHelper, ::UnitRange{Int64}) at .\\In[73]:6",
      " [11] iterate(::pHRIHelper) at .\\In[73]:5",
      " [12] top-level scope at In[74]:1",
      " [13] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "((input, output),new_state) = iterate(dtrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Linear\n",
    "    w # weight\n",
    "    b # bias\n",
    "\n",
    "    function Linear(inputsize, outputsize; atype=array_type, scale::Float64=0.01)\n",
    "        new(Param(convert(atype,randn(outputsize,inputsize)*scale)),Param(convert(atype,zeros(outputsize,1))))\n",
    "    end\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    return l.w*x.+l.b;\n",
    "end\n",
    "\n",
    "mutable struct Hidden\n",
    "    w # weight\n",
    "    b # bias\n",
    "    fun # non-linear activation function like relu or tanh\n",
    "\n",
    "    function Hidden(inputsize, outputsize, fun=relu, atype=array_type, scale=0.1)\n",
    "        w = Param(convert(atype,randn(outputsize,inputsize)*scale));\n",
    "        b = Param(convert(atype,zeros(outputsize,1)));\n",
    "         new(w,b,fun)\n",
    "    end\n",
    "end\n",
    "\n",
    "function (l::Hidden)(x)\n",
    "    return l.fun.(l.w*x.+l.b);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct pHRITrainer\n",
    "    hidden_input::Hidden\n",
    "    rnn::RNN\n",
    "    hidden::Linear\n",
    "end\n",
    "\n",
    "function pHRITrainer(input_size, hidden_size, output_size, atype=array_type)\n",
    "    hidden_input = Hidden(input_size,hidden_size)\n",
    "    rnn = RNN(hidden_size,hidden_size; numLayers=2,rnnType=:lstm);\n",
    "    hidden = Linear(hidden_size,output_size)\n",
    "    return pHRITrainer(hidden_input,rnn, hidden)\n",
    "end \n",
    "\n",
    "function (m::pHRITrainer)(x)\n",
    "    dim = size(x)\n",
    "    a = m.hidden_input(reshape(x,size(x,1),:))\n",
    "    b = m.rnn(reshape(a,size(a,1),dim[2],dim[3]));\n",
    "    c = m.hidden(reshape(b,size(b,1),:));\n",
    "    output = reshape(c,size(c,1),dim[2],dim[3]);\n",
    "    return output;\n",
    "end\n",
    "\n",
    "function (m::pHRITrainer)(data::pHRIHelper)\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for (x,y) in data\n",
    "        (loss,number) = nll(model(x),y;average=false)\n",
    "        total_loss += loss\n",
    "        count += number\n",
    "    end\n",
    "    return total_loss/count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accurasix (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(model::pHRITrainer, data; average=true)\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for (x,y) in data\n",
    "        (loss,number) = nll(model(x),y;average=false)\n",
    "        total_loss += loss\n",
    "        count += number\n",
    "    end\n",
    "    average && return total_loss/count\n",
    "    return total_loss, count\n",
    "end\n",
    "\n",
    "function accurasix(model::pHRITrainer, data)\n",
    "    ncorrect = 0\n",
    "    ntokens = 0\n",
    "    for (x, ygold) in data\n",
    "        scores = model(x)\n",
    "        ntokens += length(ygold)\n",
    "        ypred = map( y -> y[1], argmax(scores, dims=1))\n",
    "        ncorrect += sum(ygold .== ypred')\n",
    "    end\n",
    "    return ncorrect / ntokens\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), steps=1000) do y losses = [ loss(model, d) for d in (dev,tst...) ]\n",
    "        if losses[1] < bestloss\n",
    "            bestmodel, bestloss = deepcopy(model), losses[1]\n",
    "        end\n",
    "        return (losses...,)\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Out of GPU memory trying to allocate 1.008 MiB\nEffective GPU memory usage: 99.97% (1.999 GiB/2.000 GiB)\nCUDA allocator usage: 1.526 GiB\nbinned usage: 116.594 KiB (116.594 KiB allocated, 0 bytes cached)\nDiscrepancy of 1.526 GiB between memory pool and allocator!\n",
     "output_type": "error",
     "traceback": [
      "Out of GPU memory trying to allocate 1.008 MiB\nEffective GPU memory usage: 99.97% (1.999 GiB/2.000 GiB)\nCUDA allocator usage: 1.526 GiB\nbinned usage: 116.594 KiB (116.594 KiB allocated, 0 bytes cached)\nDiscrepancy of 1.526 GiB between memory pool and allocator!\n",
      "",
      "Stacktrace:",
      " [1] alloc at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\pool.jl:298 [inlined]",
      " [2] CUDA.CuArray{UInt8,1}(::UndefInitializer, ::Tuple{Int64}) at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:20",
      " [3] CuArray at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:76 [inlined]",
      " [4] CuArray at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:77 [inlined]",
      " [5] KnetPtrCu(::Int64) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\kptr.jl:229",
      " [6] Knet.KnetArrays.KnetPtr(::Int64) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\kptr.jl:107",
      " [7] KnetArray at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:75 [inlined]",
      " [8] convert at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:127 [inlined]",
      " [9] convert(::Type{KnetArray{Float32,N} where N}, ::Array{Float32,3}) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:126",
      " [10] RNN(::Int64, ::Int64; h::Nothing, c::Nothing, rnnType::Symbol, bidirectional::Bool, skipInput::Bool, numLayers::Int64, dropout::Float64, winit::typeof(Knet.Ops20.xavier), binit::typeof(zeros), finit::typeof(ones), algo::Int64, seed::Int64, atype::Type, dataType::Nothing, usegpu::Nothing, handle::Nothing) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\ops20\\rnn.jl:178",
      " [11] pHRITrainer at .\\In[76]:9 [inlined]",
      " [12] pHRITrainer(::Int64, ::Int64, ::Int64) at .\\In[76]:8",
      " [13] top-level scope at In[79]:5",
      " [14] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "Random.seed!(1)\n",
    "\n",
    "dtrn = pHRIHelper(train_data;shuffled=false);\n",
    "dtst = pHRIHelper(test_data;shuffled=false);\n",
    "model = pHRITrainer(3, 128, 3)\n",
    "epochs=1;\n",
    "\n",
    "ctrn = []\n",
    "for b in dtrn\n",
    "   push!(ctrn,b) \n",
    "end\n",
    "\n",
    "trnx10 = collect(flatten(ctrn for i in 1:epochs))\n",
    "\n",
    "trn20 = []\n",
    "counter = 0\n",
    "for d in dtrn\n",
    "    if counter > 20 \n",
    "        break\n",
    "    end\n",
    "    push!(trn20,d)\n",
    "    counter +=1\n",
    "end\n",
    "\n",
    "dev = []\n",
    "for b in dtst\n",
    "   push!(dev,b) \n",
    "end\n",
    "\n",
    "model = train!(model, trnx10, dev, trn20)\n",
    "\n",
    "#display(model(dtrn))\n",
    "#display(nll(model;data=dtrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Out of GPU memory trying to allocate 34.375 MiB\nEffective GPU memory usage: 98.36% (1.967 GiB/2.000 GiB)\nCUDA allocator usage: 1.466 GiB\nbinned usage: 101.938 KiB (101.938 KiB allocated, 0 bytes cached)\nDiscrepancy of 1.466 GiB between memory pool and allocator!\n",
     "output_type": "error",
     "traceback": [
      "Out of GPU memory trying to allocate 34.375 MiB\nEffective GPU memory usage: 98.36% (1.967 GiB/2.000 GiB)\nCUDA allocator usage: 1.466 GiB\nbinned usage: 101.938 KiB (101.938 KiB allocated, 0 bytes cached)\nDiscrepancy of 1.466 GiB between memory pool and allocator!\n",
      "",
      "Stacktrace:",
      " [1] alloc at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\pool.jl:298 [inlined]",
      " [2] CUDA.CuArray{UInt8,1}(::UndefInitializer, ::Tuple{Int64}) at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:20",
      " [3] CuArray at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:76 [inlined]",
      " [4] CuArray at C:\\Users\\berkg\\.julia\\packages\\CUDA\\YeS8q\\src\\array.jl:77 [inlined]",
      " [5] KnetPtrCu(::Int64) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\kptr.jl:229",
      " [6] Knet.KnetArrays.KnetPtr(::Int64) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\kptr.jl:107",
      " [7] KnetArray at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\knetarrays\\karray.jl:80 [inlined]",
      " [8] rnnworkspace at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\ops20_gpu\\rnn.jl:218 [inlined]",
      " [9] _rnnforw(::KnetArray{Float32,3}, ::KnetArray{Float32,3}, ::Nothing, ::Nothing; rnn::RNN, handle::Ptr{Nothing}, batchSizes::Nothing, hy::Bool, cy::Bool) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\ops20_gpu\\rnn.jl:143",
      " [10] forw(::Function, ::Param{KnetArray{Float32,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Symbol,Any,NTuple{5,Symbol},NamedTuple{(:rnn, :handle, :batchSizes, :hy, :cy),Tuple{RNN,Ptr{Nothing},Nothing,Bool,Bool}}}) at C:\\Users\\berkg\\.julia\\packages\\AutoGrad\\TTpeo\\src\\core.jl:66",
      " [11] #_rnnforw#160 at .\\none:0 [inlined]",
      " [12] rnnforw(::RNN, ::Param{KnetArray{Float32,3}}, ::AutoGrad.Result{KnetArray{Float32,3}}, ::Nothing, ::Nothing; handle::Ptr{Nothing}, batchSizes::Nothing, hy::Bool, cy::Bool) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\ops20_gpu\\rnn.jl:102",
      " [13] (::RNN)(::AutoGrad.Result{KnetArray{Float32,3}}; batchSizes::Nothing) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\ops20\\rnn.jl:351",
      " [14] (::RNN)(::AutoGrad.Result{KnetArray{Float32,3}}) at C:\\Users\\berkg\\.julia\\packages\\Knet\\C0PoK\\src\\ops20\\rnn.jl:331",
      " [15] (::pHRITrainer)(::KnetArray{Float32,3}) at .\\In[44]:17",
      " [16] loss(::pHRITrainer, ::pHRIHelper; average::Bool) at .\\In[45]:5",
      " [17] loss at .\\In[45]:2 [inlined]",
      " [18] train!(::pHRITrainer, ::pHRIHelper, ::pHRIHelper) at .\\In[48]:2",
      " [19] top-level scope at In[48]:23",
      " [20] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), steps=1000) do y\n",
    "        losses = [ loss(model, d) for d in (dev,tst...) ]\n",
    "        if losses[1] < bestloss\n",
    "            bestmodel, bestloss = deepcopy(model), losses[1]\n",
    "        end\n",
    "        return (losses...,)\n",
    "    end\n",
    "    return bestmodel\n",
    "end\n",
    "\n",
    "function mytrain!(model::pHRITrainer, train_data::pHRIHelper, test_data::pHRIHelper,period::Int=10, iters::Int=500)\n",
    "    train_loss, test_loss = Any[],Any[]\n",
    "    for i in 0:period:iters\n",
    "        train_loss = [train_loss; model(train_data)]\n",
    "        test_loss = [test_loss; model(test_data)]\n",
    "        sgd!(model,take(cycle(train_data),period))\n",
    "    end\n",
    "    return 0:period:iters, train_loss, test_loss\n",
    "end\n",
    "\n",
    "iters, trnloss, tstloss = train!(model, dtrn, dtst)\n",
    "@info \"mytrain! tests passed\"\n",
    "plot(iters, trnloss, label=\"train\", xlabel=\"iterations\", ylabel=\"loss\")\n",
    "plot!(iters, tstloss, label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in takenth(progress(adam(model,lr=0.15,ncycle(dtrn,100))),dtrn.ninstances); display(x) end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mytrain!(model::pHRITrainer, dtrn::pHRIHelper, dtst::pHRIHelper; lr_input=0.15, epoch::Int=100, optimizer)\n",
    "    train_loss = Array{Float64,1}()\n",
    "    test_loss = Array{Float64,1}()\n",
    "    train_error = Array{Float64,1}()\n",
    "    test_error = Array{Float64,1}()\n",
    "    for x in takenth(progress(optimizer(model,lr=lr_input,ncycle(dtrn,epoch))),dtrn.ninstances)\n",
    "        push!(train_loss,model(dtrn))\n",
    "        push!(test_loss,model(dtst))\n",
    "        push!(train_error, 1-accuracy(model,data = dtrn))\n",
    "        push!(test_error, 1-accuracy(model,data = dtst))\n",
    "    end\n",
    "    return 1:epoch, train_loss, test_loss, train_error, test_error\n",
    "end\n",
    "\n",
    "function train_n_show(model,dtrn,dtst,epoch_,learning_rate,optimizer_,Title)\n",
    "    epoch = Array{Int64,1}()    \n",
    "    trnloss = Array{Float64,1}()\n",
    "    tstloss = Array{Float64,1}()\n",
    "    trnerror = Array{Float64,1}()\n",
    "    tsterror = Array{Float64,1}()\n",
    "    epoch, trnloss, tstloss, trnerror, tsterror = mytrain!(model,dtrn,dtst,epoch = epoch_,lr_input = learning_rate ,optimizer=optimizer_);\n",
    "    loss_graph = plot(epoch, trnloss, label=\"Training Loss\" , xlabel = \"epochs\", ylabel = \"loss\", title=Title)\n",
    "    plot!(epoch, tstloss, label=\"Test Loss\")\n",
    "    error_graph = plot(epoch, trnerror, label=\"Training Error\" , xlabel = \"epochs\", ylabel = \"error\", title=Title)\n",
    "    plot!(epoch, tsterror, label=\"Test Error\")\n",
    "    display(loss_graph)\n",
    "    display(error_graph)\n",
    "    print(\"Training Loss: \",round(minimum(trnloss),digits=4),\" Test Loss: \", round(minimum(tstloss),digits=4))\n",
    "    print(\"\\nTraining Error: \",round(minimum(trnerror),digits=4),\" Test Error: \", round(minimum(tsterror),digits=4))\n",
    "end\n",
    "\n",
    "\n",
    "iters, trnloss, tstloss = train_n_show(model, dtrn, dtst,80,0.0001,adam,\"Let's See\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle(dtrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
